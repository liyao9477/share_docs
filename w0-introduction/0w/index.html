<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>0w - liyao碎片机</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "0w";
    var mkdocs_page_input_path = "w0-introduction/0w.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> liyao碎片机</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Index</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../git/">Git</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../r/">R</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../linux/">Linux</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../linux_cmd/">Linux_cmd</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../cmd_line/">Cmd_line</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../awe_python/">Awe_python</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../awe_spider/">Awe_spider</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../data_science2/">Data_science</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../machine_learning/">ML</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../ml_tutor/">ML_tutor</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../mysql_chefs/">Mysql_chefs</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../21m_mysql/">Mysql_21m</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../front/">Front</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../math/">Math</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../statistic_python/">Statistic_python</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../dm_da/">DM_DA</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../dm_r/">DM_R</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../dm_python/">DM_Python</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../sci/">Sci</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../utilities/">Uti</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../web/">Web</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../ajenti/">ajenti</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../macos_app/">Macos_app</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../r4ds/">r4ds</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../python_spider/">Python_spider</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../p_books/">P_books</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">liyao碎片机</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
    
    <li>0w</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h2 id="_1">数据挖掘概览</h2>
<h3 id="_2">一、引子：关于数据利用的故事</h3>
<p><a href="http://news.ifeng.com/history/zhongguojindaishi/detail_2013_03/18/23226701_0.shtml">林彪发现敌军指挥部</a></p>
<p>在这个故事中，指挥官做了这样几件有关联的事情。一并称之为”数据闭环“。
- 不间断的收集战场数据；
- 基于某个指标抽象出战场实际；
- 对指标进行分析建模，发现一个机会；
- 基于分析结果进行战场决断，获取最大利益。</p>
<p>将指挥官换成CEO，就是商业数据闭环，基本上所有的商业数据应用，离不开这个套路。</p>
<p>你觉得指挥官建立了什么模型？先想想，别急着看<a href="https://zh.wikipedia.org/wiki/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B">答案</a></p>
<h3 id="_3">什么是数据闭环</h3>
<ul>
<li>度量商业行动：例如用一个指标测量用户响应率</li>
<li>识别商业机会：规划光棍节新产品或新活动，理解客户数据的波动，评价营销活动的结果</li>
<li>将数据转为知识：通过数据挖掘实施</li>
<li>基于知识行动：通常结合现有的业务流程，客户出现时推送信息，不同客户给予不同的资源</li>
</ul>
<h3 id="_4">数据利用的四层境界</h3>
<ul>
<li>数据：
数据底层，原始数据的汪洋大海。形态：数据库。功能：直接取数</li>
<li>信息：
基于数据提炼得到的指标，新客有多少？老客有多少？老客都有什么特征，新客都有什么特征？形态：汇总报表。功能：指标提供，回答过去已经发生了什么的问题，业务人员运用得当也可以解决很多问题。</li>
<li>知识：
基于信息建立各指标之间的关系模型。什么情况下新客会转化为老客？模型结果。形态：模型，功能：回答为什么的问题，解释关系和因果，预测未来</li>
<li>智慧：
将知识融入决策流程，将模型嵌入产品。我们要怎么做，才会让新客转化为老客。形态：数据产品。功能：控制未来</li>
</ul>
<h3 id="_5">数据产品</h3>
<ul>
<li>数据产品就是给决策者提供行动信息的载体，例如<ul>
<li>Amazon的商品推荐</li>
<li>天气预报</li>
<li>Stock Market Predictions</li>
<li>Production Process Improvements</li>
<li>Health Diagnosis</li>
<li>Flu Trend Predictions</li>
</ul>
</li>
<li>有些看起来也能提供决策者行动信息，如黄历，星相，但它们不是基于数据的洞察。</li>
</ul>
<h3 id="_6">二、什么是数据挖掘</h3>
<ul>
<li>数据挖掘也称为知识发现。是一个去粗存精、去伪存真的过程。是从大量数据中提取、归纳有用知识的过程和方法。将其用于决策，可以提高人类的福利。</li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%BC%80%E6%99%AE%E5%8B%92%E5%AE%9A%E5%BE%8B">开普勒三大定律</a>
开普勒的老师第谷收集了大量天文观测数据，但却是开普勒通过研究数据找到背后的规律</li>
<li>几个相关概念<ul>
<li>机器学习</li>
<li>统计理论</li>
<li>数据科学</li>
<li>模式识别</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>需要算法开发</th>
<th>不需要算法开发</th>
</tr>
</thead>
<tbody>
<tr>
<td>需要数据开发</td>
<td>数据科学家</td>
<td>数据挖掘工程师</td>
</tr>
<tr>
<td>不需要数据开发</td>
<td>算法工程师</td>
<td>kaggle玩家</td>
</tr>
</tbody>
</table>
<h3 id="_7">三、数据挖掘和我们的关系</h3>
<h3 id="_8">为何需要数据挖掘：</h3>
<ul>
<li>如果没有数据，可以用什么决策？（直觉，经验归纳，逻辑推理，算命）</li>
<li>需要数据，因为数据就是现实世界的历史痕迹，需要通过各种痕迹来推断未来，数据就是历史，挖掘就是归纳。</li>
<li>数据太多，人脑无法直接处理。记录的数据越来越多，形式和来源都越来越复杂。自然产生的数据，人类社会产生的数据（社交网络，文本，图像，语音，视频......）</li>
<li>所以需要挖掘工具和方法的帮助。</li>
</ul>
<h3 id="_9">数据挖掘为什么火？</h3>
<ul>
<li>当前的各项前提条件已经具备。<ul>
<li>硬件价格的下降，使数据的存储和运算成本更低。</li>
<li>个人和创业公司得以进入数据领域。</li>
<li>开源软件工具和公开课分享使跨界更为容易。</li>
<li>不同学科的壁垒被打破，可以较为容易的获得并学习其它学科的知识和工具，成为专业余人士。</li>
</ul>
</li>
</ul>
<h3 id="_10">数据挖掘和谁打交道</h3>
<ul>
<li>产品：侧重于底层数据框架搭建，数据报表开发，数据产品开发，例如淘宝的数据魔方的开发工作，这类工作需要很强的软件开发背景。</li>
<li>模型：侧重于对数据的研究，用统计理论或机器学习的方法对数据进行分析建模，例如广告的点击率分析建模，这类工作需要丰富的统计理论和模型算法知识。</li>
<li>美学：侧重于对数据的创作，用WEB技术进行数据可视化或者制作信息图，例如卫报的数据网站，需要很强的可视化能力和前端技术。</li>
<li>价值：侧重于数据中包含的商业价值研究，强调对专业领域的业务理解和交流沟通，例如咨询公司发布的商业分析报告，需要广泛的业务知识和商业敏感度。</li>
</ul>
<h3 id="_11">应用领域有哪些：</h3>
<ul>
<li>商业零售</li>
<li>医疗</li>
<li>金融</li>
<li>太空探索</li>
<li>文字语音识别</li>
<li>下棋。。。</li>
</ul>
<h3 id="_12">四、什么是数据挖掘模型？</h3>
<ul>
<li>一个关于模型的浅显例子：如何判断一个未切开的西瓜甜不甜？</li>
<li>
<p>可能的方案：</p>
<ul>
<li>准备N个西瓜</li>
<li>设计M个变量或指标（特征工程），重量、花纹、茎叶的新鲜程度、卖家的位置...，切开前记录这些指标，记为X。</li>
<li>切开后让n个人品尝打分(0表示不甜，1表示甜)，记为Y。</li>
<li>使用其中一部分数据，结合分类算法对X和Y的关系进行建模。</li>
<li>用剩下另一部分数据，检查模型的效果。</li>
<li>把模型的逻辑写成一个APP放到应用市场上，持续收获数据，改进模型。</li>
</ul>
</li>
<li>
<p>一个复杂的例子，如何判断一个老人未来是否会得痴呆症（思考思考）</p>
</li>
</ul>
<h3 id="_13">商业中使用模型的例子：</h3>
<ul>
<li>银行的信用卡发放：</li>
</ul>
<p>银行在信用卡发放的时候会进行审核。审核某个人的资格是否符合条件以授信。在传统的审核工作，这种事是人工来做的，申请人填一张表，写上个人的年龄、职业、收入等信息（X变量）。交给有经验的银行风控师，他们来进行评价，是发信用卡，还是不发信用卡。</p>
<p>但在互联网时代，这种人工审核就太慢了。互联网金融的崛起就是最明显的趋势。它将全网中关于个人的行为数据进行收集整合，其中有必然有一部分人已经在金融机构有过借贷行为，考察这种行为是否有违约，将其作为Y。将其它的行为数据作为X。这样就构成了一个可以喂到分类算法中的数据集。然后这个模型就可以用在未来的申请人身上，形成审核自动化系统。</p>
<ul>
<li>gmail垃圾邮件自动分类：</li>
</ul>
<p>如果你点开自己的gmail邮箱，仔细观察会发现一个垃圾邮件的标签，它平时默默的为你挡下大量的垃圾信息，而又不去干扰你，实在是数据产品的典范。那么如果你来做这种垃圾邮件的自动分类，要怎么做的呢？</p>
<p>如果我们考虑简单些，抛开一封电邮中的其它信息（发件人，IP...），而只取文本信息的话，这个问题就转为一个文本分类的问题。</p>
<p>文本的分析难点在于：文本不是给计算机阅读的，它有复杂的语言结构（语法、语义、语用），但语言中依然存在统计规律（统计语言模型）。</p>
<p>一个简单的文本分类模型：判断一封邮件是否垃圾邮件
    - 收集N个邮件
    - 从邮件中提取指标（分词，空间向量模型），构成文档-词项矩阵
    - 人工标注这些邮件是否垃圾邮件
    - 用一部分数据，结合算法对X和Y的关系进行建模。
    - 用剩下的数据，检查模型的效果。</p>
<h3 id="_14">五、数据挖掘日常工作有哪些</h3>
<ul>
<li>
<p>项目讨论和规划，就是开会。这方面工作目的主要是明确业务问题。是不是可以做？大概可以怎么做？确定了业务问题之后，需要将这个业务问题翻译成一个数据问题。</p>
</li>
<li>
<p>项目准备，准备开工干活了。这方面是最为繁琐也最容易出错的地方。需要和数据仓库的同学配合取得必要的数据，探索理解数据的业务意义，评估数据质量，根据项目需要对数据进行整理转换，做大量的特征工程的工作。</p>
</li>
<li>
<p>项目实施，即数据建模，开始拷打数据了。选择尝试不同的模型算法，从数据中得到需要的结果，然后从不同方面评价效果怎么样。</p>
</li>
<li>
<p>项目结束，交付结果。确定模型如何部署，并实施部署工作。这种部署就是模型的应用，多数情况下是将结果回写到数据库中。同时结果交付给需求方，写最终的项目报告，归档所有文件。</p>
</li>
<li>
<p>阅读文献，方法研究。在比较空闲的时间，或者遇到难题的时候，都需要去找巨人的肩膀依靠一下。</p>
</li>
</ul>
<h3 id="_15">一个典型的步骤流程</h3>
<ul>
<li>商业理解：理解业务目标和需求，并转化为数据挖掘可理解的问题定义。建模师会参加业务组的会议，主要是了解收集业务需求。</li>
<li>数据理解：筛选目标数据，检验数据质量，探索数据特征，评估可用数据。建模师会将一些初步结果呈现给业务组，得到进一步反馈。</li>
<li>数据准备：通过清洗，集成，变换，归约等处理方法构造最终数据集合。建模师开始疯狂的写SQL类的脚本去洗数据。</li>
<li>模型建立：选择和应用各种机器学习或统计方法、构建模型并调校各种参数。建模师进入炼丹阶段，期待能有好的结果。</li>
<li>模型评价：结合最初的商业目标评价并解释模型，评估其可能的商业效果。建模师将模型结果和业务团队进行沟通。</li>
<li>模型部署：按用户习惯方式实施并发布模型，提供分析结论，并持续跟踪。建模师将模型上线，监测性能。</li>
</ul>
<h3 id="_16">六、数据挖掘的任务模式</h3>
<ul>
<li>分类 Classification [Predictive]</li>
<li>聚类 Clustering [Descriptive]</li>
<li>关联规则 Association Rule Discovery [Descriptive]</li>
<li>序列挖掘 Sequential Pattern Discovery [Descriptive]</li>
<li>回归 Regression [Predictive]</li>
<li>异常检测 Deviation Detection [Predictive]</li>
</ul>
<h3 id="_17">分类方法的应用</h3>
<h3 id="_18">精准化营销</h3>
<ul>
<li>问题: 准备发售iphone新品了，哪些用户可能会买？</li>
<li>方法:</li>
<li>找到相似产品的用户行为数据，观察是否购买作为目标变量</li>
<li>收集这些用户的行为特征，作为模型的解释变量</li>
</ul>
<h3 id="_19">聚类方法的应用</h3>
<h3 id="_20">用户分群:</h3>
<ul>
<li>问题: 如何将用户分成若干组，然后针对不同用户组进行营销活动</li>
<li>方法:</li>
<li>收集用户的基本社会特征和行为特征</li>
<li>根据用户的相似程度进行聚类分组</li>
<li>根据同组的用户购买行为判断分群的效果</li>
</ul>
<h3 id="_21">关联规则应用</h3>
<h3 id="_22">相似商品推荐</h3>
<ul>
<li>关联规则是一种规律 {面包干, … } --&gt; {薯片}</li>
<li>买了面包干的用户往往也会去买薯片，可以利用这种关联规则，将若干商品一起放在货架上捆绑销售</li>
<li>不同的关联商品，暗示了不同的消费场景</li>
</ul>
<h3 id="_23">异常检测应用</h3>
<ul>
<li>从正常行为中发现不正常的行为模式</li>
<li>信用卡欺诈</li>
<li>网络入侵</li>
</ul>
<h3 id="_24">七、需要掌握哪些技能</h3>
<ul>
<li>
<p>有形的技能:</p>
<ul>
<li>理论：气宗。 例如统计理论、机器学习算法。个人体会精通理论后再做数据工作就如汤泼雪。我也承认学习理论是艰难的，但是一定要在年轻的时候读最难的书。《数学之美》中谈到，技术分为术和道两种，具体的做事方法是术，做事的原理和原则是道，只追求术的人工作很辛苦，只有掌握了道才能永远游刃有余。</li>
<li>工具：剑宗。理论不用在产品上就是王语焉的学院派。从理论到产品，需要掌握各种工具。这类工具用得熟了能事半功倍，例如R、python、SQL、hadoop这类。学习工具和学习语言一样，都要多读多写，模仿揣摩，就可以运用自如。不过迷信工具是没有意义的，没有最好的工具，只有最合适的工具。如果你是独孤求败，可以玩玄铁剑，如果你是东方不败，可以玩绣花针。</li>
<li>经验：实战。有内力有剑法，就需要下山了。对战最强悍的对手，才能让你的内力剑法融为一体。做项目，在工作解决难题，才是长进最快的。</li>
</ul>
</li>
<li>
<p>无形的气质:</p>
<ul>
<li>好奇，好奇心和兴趣是从数据中得到洞察的驱动力。有好奇心的人才会对数据有持续的热情。</li>
<li>创造，兵无常势，数据的工作都是千差万别的，虽然可以依靠一些老的经验做些照猫画虎的事。但最好还是需要根据不同的项目情况来做出判断。独立思考和创造让你走得更远。</li>
<li>求败，创造、前沿、探索性的工作，一定会有失败，快速失败，快速学习，不断修正，能够败中求胜。</li>
</ul>
</li>
</ul>
<h3 id="_25">如何培养数据挖掘的技能</h3>
<ul>
<li>两个字：自学。 “知识与耐心，是击败强者的唯一方法。”<ul>
<li>通过阅读来学习。包括了阅读经典的理论教材、代码、论文、上公开课。</li>
<li>通过牛人来学习。包括同行的聚会、讨论、大牛的博客、微博、twitter、RSS。</li>
<li>通过练习来学习。包括代码练习题、参加kaggle比赛、解决实际工作中的难题。</li>
<li>通过分享来学习。包括自己写笔记、写博客、和同事分享交流、培训新人。</li>
</ul>
</li>
</ul>
<h3 id="_26">八、经验之谈</h3>
<h4 id="_27">建模中的坑</h4>
<ul>
<li>
<p>建模过程的问题</p>
<ul>
<li>缺乏业务问题的沟通和理解</li>
<li>只关注训练数据或只过于相信数据</li>
<li>只依赖于一种技术</li>
<li>错误的变量输入</li>
</ul>
</li>
<li>
<p>挖掘结果不真实</p>
<ul>
<li>模型结果不代表任何规律</li>
<li>模型训练集可能不反映真正的总体</li>
<li>数据的详细程度有误</li>
</ul>
</li>
<li>
<p>挖掘结果没有用</p>
<ul>
<li>挖掘结果众所周知</li>
<li>挖掘结果不可用于决策</li>
</ul>
</li>
</ul>
<h4 id="_28">一点心得</h4>
<ul>
<li>
<p>提问题比回答问题更重要
    一个具体的业务痛点是数据挖掘的起点，精心计划流程步骤，业务知识贯穿挖掘建模的每个阶段。</p>
</li>
<li>
<p>对数据持谨慎的态度
    数据很可能出错，数据整理占据大部分的工作时间。</p>
</li>
<li>
<p>数据本身仅能用于描述历史
    不能展现因果，也不能预知未来。</p>
</li>
<li>
<p>数据价值体现在落地应用
    数据挖掘价值并不取决于模型的准确或稳定，取决于背后的决策组织。</p>
</li>
<li>
<p>不同的指标和模型都有其适用范围
    随时间环境变化，所有的模式都会改变，不断尝试，不断修正。</p>
</li>
<li>
<p>工作中的文档化和自动化</p>
</li>
</ul>
<h3 id="_29">一个综合案例的建模步骤</h3>
<ul>
<li>问题定义</li>
<li>数据探索</li>
<li>特征工程</li>
<li>建模和评估</li>
</ul>
<h3 id="_30">问题定义</h3>
<p>我们使用kaggle上一个经典的问题做为案例示范，即判断一个贷款者在后续两年内是否会违约的概率。</p>
<h4 id="_31">需要思考的关键问题</h4>
<ul>
<li>损失是如何发生的?</li>
<li>违约的人有哪些特点?</li>
<li>违约的占比有多少？</li>
<li>如何能改善我们的损失？</li>
</ul>
<h4 id="_32">数据下载</h4>
<p><a href="http://www.kaggle.com/c/GiveMeSomeCredit">http://www.kaggle.com/c/GiveMeSomeCredit</a></p>
<h3 id="_33">变量的意义</h3>
<ul>
<li>SeriousDlqin2yrs<ul>
<li>用户在后续两年内出现90天以上的还款逾期，这是目标变量，以下都是解释变量</li>
</ul>
</li>
<li>RevolvingUtilizationOfUnsecuredLines<ul>
<li>信用卡借款占比</li>
</ul>
</li>
<li>age<ul>
<li>借款人年龄</li>
</ul>
</li>
<li>NumberOfTime30-59DaysPastDueNotWorse<ul>
<li>过去有逾期30-59天还款的次数</li>
</ul>
</li>
<li>DebtRatio<ul>
<li>月度生活成本占月收入的比率</li>
</ul>
</li>
<li>MonthlyIncome<ul>
<li>月收入</li>
</ul>
</li>
<li>NumberOfOpenCreditLinesAndLoans<ul>
<li>包括车贷房贷在内的贷款笔数</li>
</ul>
</li>
<li>NumberOfTimes90DaysLate<ul>
<li>过去有逾期90天以上还款的次数</li>
</ul>
</li>
<li>NumberRealEstateLoansOrLines<ul>
<li>房贷的信贷次数</li>
</ul>
</li>
<li>NumberOfTime60-89DaysPastDueNotWorse<ul>
<li>过去有逾期60-89天还款的次数</li>
</ul>
</li>
<li>NumberOfDependents<ul>
<li>家庭中需要抚养者的人数</li>
</ul>
</li>
</ul>
<pre><code class="python">import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
</code></pre>

<pre><code class="python">df = pd.read_csv(&quot;data/credit-training.csv&quot;) #读取数据
df.head()
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SeriousDlqin2yrs</th>
      <th>RevolvingUtilizationOfUnsecuredLines</th>
      <th>age</th>
      <th>NumberOfTime30-59DaysPastDueNotWorse</th>
      <th>DebtRatio</th>
      <th>MonthlyIncome</th>
      <th>NumberOfOpenCreditLinesAndLoans</th>
      <th>NumberOfTimes90DaysLate</th>
      <th>NumberRealEstateLoansOrLines</th>
      <th>NumberOfTime60-89DaysPastDueNotWorse</th>
      <th>NumberOfDependents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.766127</td>
      <td>45</td>
      <td>2</td>
      <td>0.802982</td>
      <td>9120.0</td>
      <td>13</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0.957151</td>
      <td>40</td>
      <td>0</td>
      <td>0.121876</td>
      <td>2600.0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0.658180</td>
      <td>38</td>
      <td>1</td>
      <td>0.085113</td>
      <td>3042.0</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0.233810</td>
      <td>30</td>
      <td>0</td>
      <td>0.036050</td>
      <td>3300.0</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0.907239</td>
      <td>49</td>
      <td>1</td>
      <td>0.024926</td>
      <td>63588.0</td>
      <td>7</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python">df.shape # 一共15万条记录
</code></pre>

<pre><code>(150000, 11)
</code></pre>
<h3 id="_34">数据探索</h3>
<pre><code class="python">df.info() # 有缺失值
</code></pre>

<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 150000 entries, 0 to 149999
Data columns (total 11 columns):
SeriousDlqin2yrs                        150000 non-null int64
RevolvingUtilizationOfUnsecuredLines    150000 non-null float64
age                                     150000 non-null int64
NumberOfTime30-59DaysPastDueNotWorse    150000 non-null int64
DebtRatio                               150000 non-null float64
MonthlyIncome                           120269 non-null float64
NumberOfOpenCreditLinesAndLoans         150000 non-null int64
NumberOfTimes90DaysLate                 150000 non-null int64
NumberRealEstateLoansOrLines            150000 non-null int64
NumberOfTime60-89DaysPastDueNotWorse    150000 non-null int64
NumberOfDependents                      146076 non-null float64
dtypes: float64(4), int64(7)
memory usage: 12.6 MB
</code></pre>
<pre><code class="python">df.describe() # 描述性统计
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SeriousDlqin2yrs</th>
      <th>RevolvingUtilizationOfUnsecuredLines</th>
      <th>age</th>
      <th>NumberOfTime30-59DaysPastDueNotWorse</th>
      <th>DebtRatio</th>
      <th>MonthlyIncome</th>
      <th>NumberOfOpenCreditLinesAndLoans</th>
      <th>NumberOfTimes90DaysLate</th>
      <th>NumberRealEstateLoansOrLines</th>
      <th>NumberOfTime60-89DaysPastDueNotWorse</th>
      <th>NumberOfDependents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>1.202690e+05</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>150000.000000</td>
      <td>146076.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.066840</td>
      <td>6.048438</td>
      <td>52.295207</td>
      <td>0.421033</td>
      <td>353.005076</td>
      <td>6.670221e+03</td>
      <td>8.452760</td>
      <td>0.265973</td>
      <td>1.018240</td>
      <td>0.240387</td>
      <td>0.757222</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.249746</td>
      <td>249.755371</td>
      <td>14.771866</td>
      <td>4.192781</td>
      <td>2037.818523</td>
      <td>1.438467e+04</td>
      <td>5.145951</td>
      <td>4.169304</td>
      <td>1.129771</td>
      <td>4.155179</td>
      <td>1.115086</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000e+00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>0.029867</td>
      <td>41.000000</td>
      <td>0.000000</td>
      <td>0.175074</td>
      <td>3.400000e+03</td>
      <td>5.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>0.154181</td>
      <td>52.000000</td>
      <td>0.000000</td>
      <td>0.366508</td>
      <td>5.400000e+03</td>
      <td>8.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.000000</td>
      <td>0.559046</td>
      <td>63.000000</td>
      <td>0.000000</td>
      <td>0.868254</td>
      <td>8.249000e+03</td>
      <td>11.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>50708.000000</td>
      <td>109.000000</td>
      <td>98.000000</td>
      <td>329664.000000</td>
      <td>3.008750e+06</td>
      <td>58.000000</td>
      <td>98.000000</td>
      <td>54.000000</td>
      <td>98.000000</td>
      <td>20.000000</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python">df.SeriousDlqin2yrs.value_counts()
</code></pre>

<pre><code>0    139974
1     10026
Name: SeriousDlqin2yrs, dtype: int64
</code></pre>
<pre><code class="python">df.SeriousDlqin2yrs.mean() # 平均严重拖欠
</code></pre>

<pre><code>0.06684
</code></pre>
<pre><code class="python">df.NumberOfDependents.unique() # 受抚养者, 查看有多少取值
</code></pre>

<pre><code>array([  2.,   1.,   0.,  nan,   3.,   4.,   5.,   6.,   8.,   7.,  20.,
        10.,   9.,  13.])
</code></pre>
<pre><code class="python">df.NumberOfDependents.value_counts()
# 观察频数表，一半都没有, 有的话集中1-3个, 再往上较少
</code></pre>

<pre><code>0.0     86902
1.0     26316
2.0     19522
3.0      9483
4.0      2862
5.0       746
6.0       158
7.0        51
8.0        24
10.0        5
9.0         5
20.0        1
13.0        1
Name: NumberOfDependents, dtype: int64
</code></pre>
<pre><code class="python">df.groupby(&quot;SeriousDlqin2yrs&quot;).mean()
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>RevolvingUtilizationOfUnsecuredLines</th>
      <th>age</th>
      <th>NumberOfTime30-59DaysPastDueNotWorse</th>
      <th>DebtRatio</th>
      <th>MonthlyIncome</th>
      <th>NumberOfOpenCreditLinesAndLoans</th>
      <th>NumberOfTimes90DaysLate</th>
      <th>NumberRealEstateLoansOrLines</th>
      <th>NumberOfTime60-89DaysPastDueNotWorse</th>
      <th>NumberOfDependents</th>
    </tr>
    <tr>
      <th>SeriousDlqin2yrs</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.168855</td>
      <td>52.751375</td>
      <td>0.280109</td>
      <td>357.151168</td>
      <td>6747.837774</td>
      <td>8.493620</td>
      <td>0.135225</td>
      <td>1.020368</td>
      <td>0.126666</td>
      <td>0.743417</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.367282</td>
      <td>45.926591</td>
      <td>2.388490</td>
      <td>295.121066</td>
      <td>5630.826493</td>
      <td>7.882306</td>
      <td>2.091362</td>
      <td>0.988530</td>
      <td>1.828047</td>
      <td>0.948208</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python">pd.value_counts(df.NumberOfDependents).plot(kind='bar');
</code></pre>

<p><img alt="png" src="../output_23_0.png" /></p>
<pre><code class="python">pd.crosstab(df.NumberOfTimes90DaysLate, df.SeriousDlqin2yrs)
# 计算交叉频数表
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>SeriousDlqin2yrs</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>NumberOfTimes90DaysLate</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>135108</td>
      <td>6554</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3478</td>
      <td>1765</td>
    </tr>
    <tr>
      <th>2</th>
      <td>779</td>
      <td>776</td>
    </tr>
    <tr>
      <th>3</th>
      <td>282</td>
      <td>385</td>
    </tr>
    <tr>
      <th>4</th>
      <td>96</td>
      <td>195</td>
    </tr>
    <tr>
      <th>5</th>
      <td>48</td>
      <td>83</td>
    </tr>
    <tr>
      <th>6</th>
      <td>32</td>
      <td>48</td>
    </tr>
    <tr>
      <th>7</th>
      <td>7</td>
      <td>31</td>
    </tr>
    <tr>
      <th>8</th>
      <td>6</td>
      <td>15</td>
    </tr>
    <tr>
      <th>9</th>
      <td>5</td>
      <td>14</td>
    </tr>
    <tr>
      <th>10</th>
      <td>3</td>
      <td>5</td>
    </tr>
    <tr>
      <th>11</th>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>13</th>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>14</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>15</th>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>96</th>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>98</th>
      <td>121</td>
      <td>143</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python">pd.crosstab(df.age, df.NumberOfDependents)
# 年龄与受抚养者的关系
# 岁数越大抚养者会多
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>NumberOfDependents</th>
      <th>0.0</th>
      <th>1.0</th>
      <th>2.0</th>
      <th>3.0</th>
      <th>4.0</th>
      <th>5.0</th>
      <th>6.0</th>
      <th>7.0</th>
      <th>8.0</th>
      <th>9.0</th>
      <th>10.0</th>
      <th>13.0</th>
      <th>20.0</th>
    </tr>
    <tr>
      <th>age</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>21</th>
      <td>148</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22</th>
      <td>385</td>
      <td>7</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23</th>
      <td>550</td>
      <td>33</td>
      <td>13</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>24</th>
      <td>689</td>
      <td>48</td>
      <td>19</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>25</th>
      <td>774</td>
      <td>91</td>
      <td>31</td>
      <td>7</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>26</th>
      <td>946</td>
      <td>128</td>
      <td>56</td>
      <td>14</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27</th>
      <td>1001</td>
      <td>192</td>
      <td>53</td>
      <td>32</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>28</th>
      <td>1142</td>
      <td>210</td>
      <td>114</td>
      <td>45</td>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>29</th>
      <td>1195</td>
      <td>254</td>
      <td>145</td>
      <td>53</td>
      <td>14</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>30</th>
      <td>1337</td>
      <td>288</td>
      <td>178</td>
      <td>72</td>
      <td>14</td>
      <td>7</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>31</th>
      <td>1314</td>
      <td>344</td>
      <td>245</td>
      <td>91</td>
      <td>18</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>32</th>
      <td>1207</td>
      <td>380</td>
      <td>275</td>
      <td>106</td>
      <td>53</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>33</th>
      <td>1254</td>
      <td>449</td>
      <td>315</td>
      <td>140</td>
      <td>50</td>
      <td>10</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>34</th>
      <td>1152</td>
      <td>389</td>
      <td>360</td>
      <td>145</td>
      <td>65</td>
      <td>11</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>35</th>
      <td>1136</td>
      <td>418</td>
      <td>398</td>
      <td>184</td>
      <td>58</td>
      <td>15</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>36</th>
      <td>1139</td>
      <td>445</td>
      <td>486</td>
      <td>202</td>
      <td>50</td>
      <td>15</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>1088</td>
      <td>488</td>
      <td>541</td>
      <td>274</td>
      <td>77</td>
      <td>18</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>38</th>
      <td>1113</td>
      <td>484</td>
      <td>604</td>
      <td>283</td>
      <td>84</td>
      <td>26</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>39</th>
      <td>1202</td>
      <td>544</td>
      <td>691</td>
      <td>383</td>
      <td>111</td>
      <td>27</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>40</th>
      <td>1185</td>
      <td>570</td>
      <td>758</td>
      <td>391</td>
      <td>104</td>
      <td>43</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>41</th>
      <td>1193</td>
      <td>517</td>
      <td>791</td>
      <td>445</td>
      <td>113</td>
      <td>30</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>42</th>
      <td>1159</td>
      <td>526</td>
      <td>755</td>
      <td>427</td>
      <td>142</td>
      <td>38</td>
      <td>7</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>43</th>
      <td>1205</td>
      <td>556</td>
      <td>789</td>
      <td>431</td>
      <td>156</td>
      <td>33</td>
      <td>9</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>44</th>
      <td>1209</td>
      <td>574</td>
      <td>854</td>
      <td>461</td>
      <td>133</td>
      <td>32</td>
      <td>7</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>45</th>
      <td>1363</td>
      <td>608</td>
      <td>828</td>
      <td>457</td>
      <td>165</td>
      <td>35</td>
      <td>11</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>46</th>
      <td>1373</td>
      <td>695</td>
      <td>876</td>
      <td>498</td>
      <td>165</td>
      <td>35</td>
      <td>8</td>
      <td>8</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>47</th>
      <td>1439</td>
      <td>672</td>
      <td>863</td>
      <td>491</td>
      <td>148</td>
      <td>46</td>
      <td>9</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>48</th>
      <td>1509</td>
      <td>771</td>
      <td>791</td>
      <td>459</td>
      <td>157</td>
      <td>37</td>
      <td>11</td>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49</th>
      <td>1632</td>
      <td>717</td>
      <td>790</td>
      <td>439</td>
      <td>143</td>
      <td>46</td>
      <td>8</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>74</th>
      <td>1164</td>
      <td>184</td>
      <td>23</td>
      <td>4</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>75</th>
      <td>981</td>
      <td>167</td>
      <td>17</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>76</th>
      <td>933</td>
      <td>165</td>
      <td>16</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77</th>
      <td>890</td>
      <td>129</td>
      <td>11</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>78</th>
      <td>837</td>
      <td>137</td>
      <td>13</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>79</th>
      <td>770</td>
      <td>131</td>
      <td>10</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>80</th>
      <td>704</td>
      <td>109</td>
      <td>7</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>81</th>
      <td>629</td>
      <td>76</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>82</th>
      <td>527</td>
      <td>69</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>83</th>
      <td>417</td>
      <td>44</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>84</th>
      <td>406</td>
      <td>32</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>85</th>
      <td>403</td>
      <td>30</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>86</th>
      <td>318</td>
      <td>46</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>87</th>
      <td>279</td>
      <td>29</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>88</th>
      <td>244</td>
      <td>20</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>89</th>
      <td>230</td>
      <td>11</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>90</th>
      <td>148</td>
      <td>19</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>91</th>
      <td>119</td>
      <td>10</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>92</th>
      <td>75</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>93</th>
      <td>67</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>94</th>
      <td>33</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>95</th>
      <td>33</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>96</th>
      <td>12</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>97</th>
      <td>11</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98</th>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>99</th>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>101</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>102</th>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>103</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>107</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>84 rows × 13 columns</p>
</div>

<h3 id="_35">清洗数据</h3>
<pre><code class="python">import re
# 将名字都改为 snake_case
def camel_to_snake(column_name):
    &quot;&quot;&quot;
    converts a string that is camelCase into snake_case
    &quot;&quot;&quot;
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', column_name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()
camel_to_snake(&quot;javaLovesCamelCase&quot;)
</code></pre>

<pre><code>'java_loves_camel_case'
</code></pre>
<pre><code class="python">df.columns = [camel_to_snake(col) for col in df.columns]
df.columns.tolist()
</code></pre>

<pre><code>['serious_dlqin2yrs',
 'revolving_utilization_of_unsecured_lines',
 'age',
 'number_of_time30-59_days_past_due_not_worse',
 'debt_ratio',
 'monthly_income',
 'number_of_open_credit_lines_and_loans',
 'number_of_times90_days_late',
 'number_real_estate_loans_or_lines',
 'number_of_time60-89_days_past_due_not_worse',
 'number_of_dependents']
</code></pre>
<pre><code class="python">from sklearn.neighbors import KNeighborsRegressor
income_imputer = KNeighborsRegressor(n_neighbors=1)

# 数据分为两部分，有缺失的和无缺失的，用无缺失的数据建立模型来判断缺失数据的可能取值
train_w_monthly_income = df[df.monthly_income.isnull()==False]
train_w_null_monthly_income = df[df.monthly_income.isnull()==True]
</code></pre>

<pre><code class="python">cols = ['number_real_estate_loans_or_lines', 'number_of_open_credit_lines_and_loans']
income_imputer.fit(train_w_monthly_income[cols], train_w_monthly_income.monthly_income)
# 用房产贷款次数以及未结束贷款次数来训练月收入
</code></pre>

<pre><code>KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
          metric_params=None, n_jobs=1, n_neighbors=1, p=2,
          weights='uniform')
</code></pre>
<pre><code class="python">new_values = income_imputer.predict(train_w_null_monthly_income[cols])
# 再用模型预测缺失值中的月收入
</code></pre>

<pre><code class="python">train_w_null_monthly_income.ix[:,'monthly_income']=new_values
# imputation
</code></pre>

<pre><code class="python">df_imputed = train_w_monthly_income.append(train_w_null_monthly_income)
df_imputed.shape # 填充缺失值 done
</code></pre>

<pre><code>(150000, 11)
</code></pre>
<pre><code class="python">df_imputed.ix[df_imputed.number_of_dependents.isnull(),'number_of_dependents'] = -1
</code></pre>

<pre><code class="python">df_imputed.info()
</code></pre>

<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 150000 entries, 0 to 149997
Data columns (total 11 columns):
serious_dlqin2yrs                              150000 non-null int64
revolving_utilization_of_unsecured_lines       150000 non-null float64
age                                            150000 non-null int64
number_of_time30-59_days_past_due_not_worse    150000 non-null int64
debt_ratio                                     150000 non-null float64
monthly_income                                 150000 non-null float64
number_of_open_credit_lines_and_loans          150000 non-null int64
number_of_times90_days_late                    150000 non-null int64
number_real_estate_loans_or_lines              150000 non-null int64
number_of_time60-89_days_past_due_not_worse    150000 non-null int64
number_of_dependents                           150000 non-null float64
dtypes: float64(4), int64(7)
memory usage: 13.7 MB
</code></pre>
<h3 id="_36">特征工程</h3>
<pre><code class="python">df_imputed.monthly_income.hist();
</code></pre>

<p><img alt="png" src="../output_37_0.png" /></p>
<pre><code class="python">def cap_values(x, cap):
    if x &gt; cap:
        return cap
    else:
        return x
# 设定上限
df_imputed.monthly_income = df_imputed.monthly_income.apply(lambda x: cap_values(x, 15000))
</code></pre>

<pre><code class="python"># 变量离散化，分为15个bin
df_imputed['income_bins'] = pd.cut(df_imputed.monthly_income, bins=15, labels=False)
pd.value_counts(df_imputed.income_bins)
</code></pre>

<pre><code>3     23168
4     19944
5     15583
6     14475
2     14038
7     10766
8      8609
14     7775
9      7672
1      7504
10     6298
0      4994
11     4454
12     2547
13     2173
Name: income_bins, dtype: int64
</code></pre>
<pre><code class="python">df_imputed[[&quot;income_bins&quot;, &quot;serious_dlqin2yrs&quot;]].groupby(&quot;income_bins&quot;).mean()
# 每个月收入分类中统计default平均频数
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>serious_dlqin2yrs</th>
    </tr>
    <tr>
      <th>income_bins</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.051862</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.104211</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.093674</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.084168</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.073305</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.066033</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.059067</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.054338</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.050877</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.048488</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.039695</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.037270</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.040832</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.042338</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.047203</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python"># 画出图来, 可以明显发现在1-2个 bin中的 default 最多
cols = [&quot;income_bins&quot;, &quot;serious_dlqin2yrs&quot;]
df_imputed[cols].groupby(&quot;income_bins&quot;).mean().plot();
</code></pre>

<p><img alt="png" src="../output_41_0.png" /></p>
<pre><code class="python"># 以年龄来看是20-30岁最高, 另外就是100岁前后, 可能是去世了?
cols = ['age', 'serious_dlqin2yrs']
age_means = df_imputed[cols].groupby(&quot;age&quot;).mean()
age_means.plot();
</code></pre>

<p><img alt="png" src="../output_42_0.png" /></p>
<pre><code class="python">mybins = [0] + range(20, 80, 5) + [120]
df_imputed['age_bin'] = pd.cut(df_imputed.age, bins=mybins)
pd.value_counts(df_imputed['age_bin'])
</code></pre>

<pre><code>(45, 50]     18829
(50, 55]     17861
(55, 60]     16945
(60, 65]     16461
(40, 45]     16208
(35, 40]     13611
(65, 70]     10963
(30, 35]     10728
(75, 120]    10129
(25, 30]      7730
(70, 75]      7507
(20, 25]      3027
(0, 20]          0
dtype: int64
</code></pre>
<pre><code class="python">from sklearn.preprocessing import StandardScaler
# Standardize features by removing the mean and scaling to unit variance

# 将月收入标准化
df_imputed['monthly_income_scaled'] = StandardScaler().fit_transform(df_imputed.monthly_income.reshape(-1,1))
</code></pre>

<h3 id="_37">建模和评估</h3>
<pre><code class="python">df_imputed.columns
</code></pre>

<pre><code>Index([u'serious_dlqin2yrs', u'revolving_utilization_of_unsecured_lines',
       u'age', u'number_of_time30-59_days_past_due_not_worse', u'debt_ratio',
       u'monthly_income', u'number_of_open_credit_lines_and_loans',
       u'number_of_times90_days_late', u'number_real_estate_loans_or_lines',
       u'number_of_time60-89_days_past_due_not_worse', u'number_of_dependents',
       u'income_bins', u'age_bin', u'monthly_income_scaled'],
      dtype='object')
</code></pre>
<pre><code class="python"># 特征
features = ['revolving_utilization_of_unsecured_lines',
 'age',
 'number_of_time30-59_days_past_due_not_worse',
 'debt_ratio',
 'monthly_income',
 'number_of_open_credit_lines_and_loans',
 'number_of_times90_days_late',
 'number_real_estate_loans_or_lines',
 'number_of_time60-89_days_past_due_not_worse',
 'number_of_dependents',
 'income_bins',
 'age_bin',
 'monthly_income_scaled']
</code></pre>

<pre><code class="python">X = pd.get_dummies(df_imputed[features], columns = ['income_bins', 'age_bin'])
# dummy var
</code></pre>

<pre><code class="python">print X.columns.tolist()
print X.shape
</code></pre>

<pre><code>['revolving_utilization_of_unsecured_lines', 'age', 'number_of_time30-59_days_past_due_not_worse', 'debt_ratio', 'monthly_income', 'number_of_open_credit_lines_and_loans', 'number_of_times90_days_late', 'number_real_estate_loans_or_lines', 'number_of_time60-89_days_past_due_not_worse', 'number_of_dependents', 'monthly_income_scaled', 'income_bins_0', 'income_bins_1', 'income_bins_2', 'income_bins_3', 'income_bins_4', 'income_bins_5', 'income_bins_6', 'income_bins_7', 'income_bins_8', 'income_bins_9', 'income_bins_10', 'income_bins_11', 'income_bins_12', 'income_bins_13', 'income_bins_14', 'age_bin_(0, 20]', 'age_bin_(20, 25]', 'age_bin_(25, 30]', 'age_bin_(30, 35]', 'age_bin_(35, 40]', 'age_bin_(40, 45]', 'age_bin_(45, 50]', 'age_bin_(50, 55]', 'age_bin_(55, 60]', 'age_bin_(60, 65]', 'age_bin_(65, 70]', 'age_bin_(70, 75]', 'age_bin_(75, 120]']
(150000, 39)
</code></pre>
<pre><code class="python">y = df_imputed.serious_dlqin2yrs # target
</code></pre>

<pre><code class="python">from sklearn.cross_validation import train_test_split
train_X, test_X, train_y, test_y = train_test_split(X, y ,train_size=0.7,random_state=1)
# 70% 是 train data
</code></pre>

<pre><code class="python">print train_X.shape
print test_X.shape
</code></pre>

<pre><code>(105000, 39)
(45000, 39)
</code></pre>
<pre><code class="python">from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
</code></pre>

<pre><code class="python">clf = LogisticRegression() # logit 逻辑回归
clf.fit(train_X,train_y)
</code></pre>

<pre><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
</code></pre>
<pre><code class="python">clf.predict_proba(test_X) # 预测概率
</code></pre>

<pre><code>array([[ 0.92834155,  0.07165845],
       [ 0.96492419,  0.03507581],
       [ 0.95753197,  0.04246803],
       ...,
       [ 0.96021551,  0.03978449],
       [ 0.87166534,  0.12833466],
       [ 0.9777555 ,  0.0222445 ]])
</code></pre>
<pre><code class="python">from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix
# 评价方法
</code></pre>

<pre><code class="python">preds = clf.predict(test_X)
confusion_matrix(test_y, preds)
</code></pre>

<pre><code>array([[41880,    88],
       [ 2908,   124]])
</code></pre>
<pre><code class="python">print classification_report(test_y, preds, labels=[0, 1])
</code></pre>

<pre><code>             precision    recall  f1-score   support

          0       0.94      1.00      0.97     41968
          1       0.58      0.04      0.08      3032

avg / total       0.91      0.93      0.91     45000
</code></pre>
<pre><code class="python">pre = clf.predict_proba(test_X)
roc_auc_score(test_y,pre[:,1])
</code></pre>

<pre><code>0.7078206950866951
</code></pre>
<pre><code class="python">fpr, tpr, thresholds = roc_curve(test_y,pre[:,1])
plt.plot(fpr,tpr,);
</code></pre>

<p><img alt="png" src="../output_60_0.png" /></p>
<pre><code class="python"># 随机森林分类器
clf = RandomForestClassifier()
clf.fit(train_X,train_y)
preds = clf.predict(test_X)
print classification_report(test_y, preds, labels=[0, 1])
</code></pre>

<pre><code>             precision    recall  f1-score   support

          0       0.94      0.99      0.97     41968
          1       0.51      0.15      0.24      3032

avg / total       0.91      0.93      0.92     45000
</code></pre>
<pre><code class="python">pre = clf.predict_proba(test_X)
roc_auc_score(test_y,pre[:,1])
</code></pre>

<pre><code>0.7867644886115015
</code></pre>
<h2 id="auc078">练习： 你来改进这个挖掘的结果，使auc可以比0.78更大</h2>
<pre><code class="python">df_imputed.to_csv('df_imputed',index = False)
</code></pre>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
